{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincelemke99/Bachelor-Thesis/blob/main/finales_lead_predication_one_hot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b99N5mGMdG0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864c0753-22c1-4fd6-e9a6-d3e7cf268c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#!pip install pandas category_encoders scikit-learn tensorflow --q\n",
        "!pip install tensorflow==2.12.0 --q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "# Import machine learning libraries\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    confusion_matrix\n",
        ")\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import mutual_info_classif"
      ],
      "metadata": {
        "id": "3PWBED5VdJxp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print(\"Authenticated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "fWIndaM6dLTZ",
        "outputId": "8a350fac-6827-48a2-f37f-de81e36c6b89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-53c51baee2a7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Authenticated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    282\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = 'prj-snd-ew3-vschmitt'"
      ],
      "metadata": {
        "id": "l97UbrNWdM0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=PROJECT_ID)"
      ],
      "metadata": {
        "id": "HwLowiLLdOBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BQ_PROJECT = PROJECT_ID\n",
        "BQ_DATASET = 'lead_prediction'\n",
        "BQ_TABLE = 'trainings_data'"
      ],
      "metadata": {
        "id": "P87AToqDdQSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL query to select data\n",
        "query = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    # Execute the query and convert the result to a pandas DataFrame\n",
        "    df = client.query(query=query).to_dataframe()\n",
        "    print(\"Query executed successfully and DataFrame is ready.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "X80IH82mdRZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "E0JLIgOYdS9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ll6eF2r4dUPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Lead_ID',], axis=\"columns\", inplace=True)"
      ],
      "metadata": {
        "id": "6_G6oJaldVRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'Lead_Source' : 'Lead Source', 'Lead_Source_Detail' : 'Lead Source Detail',\n",
        "                   'Name_Case' : 'Name Case', 'has_Phone' : 'has Phone', 'Accept_Data_Policy' : 'Accept Data Policy',\n",
        "                   'Conversion_Type' : 'Conversion Type', 'Study_Model' : 'Study Model', 'Type_of_Study_Program' : 'Type of Study Program',\n",
        "                   'Study_Location' : 'Study Location', 'Study_Program' : 'Study Program', 'Sum_of_Study_Interests' : 'Sum of Study Interests' , 'Domain_Type' : 'Domain Type' },inplace=True)\n"
      ],
      "metadata": {
        "id": "-d2uz9vGdXAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "u3S3j5J3daXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum().to_frame(name='Missing Values').sort_values('Missing Values', ascending=False)"
      ],
      "metadata": {
        "id": "mKdvsSxfddAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of missing values for each column\n",
        "percentage_missing = df.isnull().sum() * 100 / len(df)\n",
        "# Create a DataFrame to display the missing values\n",
        "missing_values_df = percentage_missing.to_frame(name='Missing Values').sort_values('Missing Values', ascending=False)\n",
        "# Display the DataFrame\n",
        "missing_values_df"
      ],
      "metadata": {
        "id": "G1oh8Lutdeb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Korrelation zwischen den fehlenden Werten\n",
        "correlation_matrix = df[['Host', 'Conversion Type', 'Gender']].isnull().corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='viridis')\n",
        "plt.title('Korrelation der fehlenden Werte')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yq5wg_EPdfsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogramme\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for i, column in enumerate(['Host', 'Conversion Type', 'Gender']):\n",
        "    sns.histplot(df[column], kde=False, ax=axes[i])\n",
        "    axes[i].set_title(f'Histogram of {column}')\n",
        "    axes[i].set_xlabel(column)\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Boxplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for i, column in enumerate(['Host', 'Conversion Type', 'Gender']):\n",
        "    sns.boxplot(y=df[column], ax=axes[i])\n",
        "    axes[i].set_title(f'Boxplot of {column}')\n",
        "    axes[i].set_ylabel(column)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rYnRRfXGdgXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Host'].value_counts()"
      ],
      "metadata": {
        "id": "DU_K8_zldiSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unwanted_hosts = ['staging.hs-fresenius.de', 'hsf035.dev.360vier.net', 'b2uxwopd.myraidbox.de', 'digital-health-school.de']\n",
        "\n",
        "# Filter the DataFrame\n",
        "df = df[~df['Host'].isin(unwanted_hosts)]"
      ],
      "metadata": {
        "id": "rLcDVZNndjwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unwanted_Lead_Source = ['-149307507Publisher', 'Not Found']\n",
        "\n",
        "# Filter the DataFrame\n",
        "df = df[~df['Lead Source'].isin(unwanted_Lead_Source )]"
      ],
      "metadata": {
        "id": "kadOrEIodlGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Conversion Type'] = df['Conversion Type'].fillna('Infomaterial')"
      ],
      "metadata": {
        "id": "_402rOaddmTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gender'] = df['Gender'].fillna('weiblich')"
      ],
      "metadata": {
        "id": "dBc0DB9Ddnki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Host'] = df['Host'].fillna('www.hs-fresenius.de')"
      ],
      "metadata": {
        "id": "oOtnOV7sdrto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of missing values for each column\n",
        "percentage_missing = df.isnull().sum() * 100 / len(df)\n",
        "# Create a DataFrame to display the missing values\n",
        "missing_values_df = percentage_missing.to_frame(name='Missing Values').sort_values('Missing Values', ascending=False)\n",
        "# Display the DataFrame\n",
        "missing_values_df"
      ],
      "metadata": {
        "id": "Hvg6hClTds63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "_dJHdRIDduZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum().to_frame(name='Missing Values').sort_values('Missing Values', ascending=False)"
      ],
      "metadata": {
        "id": "z9walqzVdv3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "sns.countplot(x='is_converted', data=df)\n",
        "plt.title('No of Unsuccessful Leads vs Successful Converted Leads', color='blue')\n",
        "plt.xticks(np.arange(2), ('Unsuccessful', 'Successful'))\n",
        "plt.xlabel('Conversion Status')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6OFH6Lu3dxri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_leads = len(df)\n",
        "successful_leads = df['is_converted'].sum()\n",
        "conversion_rate = (successful_leads / total_leads) * 100\n",
        "print(f'Conversion Rate: {conversion_rate:.2f}%')"
      ],
      "metadata": {
        "id": "BdgRQwX1dy-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a crosstab DataFrame for demonstration\n",
        "crosstab_df = pd.crosstab(index=df['Lead Source'], columns='count')"
      ],
      "metadata": {
        "id": "QUjFW5Jpd0LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_frequency_and_percentage(feature, df, category_df, another_row=False, height=8, ylabels=[]):\n",
        "    if another_row:\n",
        "        fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10, height * 2))\n",
        "    else:\n",
        "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 6))\n",
        "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "\n",
        "    # Get top 5 categories by frequency\n",
        "    top_categories = category_df[feature].value_counts().nlargest(5).index\n",
        "\n",
        "    # Frequency plot for top 5 categories\n",
        "    ax1.set_title(f'Frequency Plot of {feature}', color='blue')\n",
        "    ax1.set_ylabel(feature)\n",
        "    ax1.set_xlabel('count')\n",
        "    sns.countplot(y=feature, data=category_df[category_df[feature].isin(top_categories)],\n",
        "                  order=top_categories, ax=ax1, color='green')\n",
        "    if ylabels:\n",
        "        ax1.set_yticklabels(ylabels)\n",
        "\n",
        "    # Calculate count of converted leads for top 5 categories\n",
        "    converted_counts = df[df['is_converted'] == True][feature].value_counts()\n",
        "    converted_counts = converted_counts[converted_counts.index.isin(top_categories)]\n",
        "\n",
        "    # Converted leads plot for top 5 categories\n",
        "    ax2.set_title('Converted Leads Count', color='blue')\n",
        "    ax2.set_ylabel(feature)\n",
        "    ax2.set_xlabel('count')\n",
        "    converted_counts.sort_values().plot(kind='barh', ax=ax2, color='orange')\n",
        "    if ylabels:\n",
        "        ax2.set_yticklabels(ylabels)\n",
        "\n",
        "    # Calculate and display overall conversion rate\n",
        "    total_leads = len(df)\n",
        "    successful_leads = df['is_converted'].sum()\n",
        "    conversion_rate = (successful_leads / total_leads) * 100\n",
        "    fig.suptitle(f'Overall Conversion Rate: {conversion_rate:.2f}%', fontsize=14, color='red')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E2-X_Jsnd1wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_conversion_rate(df, is_converted_column, feature):\n",
        "    \"\"\"\n",
        "    Plots the conversion rate for a specified feature.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): The dataframe containing the data.\n",
        "    is_converted_column (str): The name of the column indicating if a conversion occurred.\n",
        "    feature (str): The feature for which to calculate and plot the conversion rate.\n",
        "    \"\"\"\n",
        "    # Filter data where is_converted is True\n",
        "    df_converted = df[df[is_converted_column] == True]\n",
        "\n",
        "    # Calculate the count of conversions for each unique value in the feature\n",
        "    converted_counts = df_converted[feature].value_counts()\n",
        "\n",
        "    # Calculate the percentage of each unique value within the converted data\n",
        "    conversion_rate = (converted_counts / converted_counts.sum()) * 100\n",
        "    conversion_rate = conversion_rate.sort_values(ascending=False)\n",
        "\n",
        "    # Plot bar chart\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    conversion_rate.plot(kind='bar')\n",
        "    plt.title(f'Percentage of Converted Users by {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Percentage of Converted Users (%)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WtqOpbmMd3ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frequency_and_percentage('Lead Source', df, df, True, 6)"
      ],
      "metadata": {
        "id": "zrsCRo9xd513"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Lead Source')"
      ],
      "metadata": {
        "id": "OLWrWxxld7Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_frequency_and_percentage('Lead_Source_Detail', df, df, True, 6)\n",
        "plot_frequency_and_percentage('Lead Source Detail', df, df, another_row=False, height=8, ylabels=[])"
      ],
      "metadata": {
        "id": "nX3B3m4vd8aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for converted leads\n",
        "converted_leads = df[df['is_converted'] == True]\n",
        "\n",
        "# Aggregate the data for Lead Source and Lead Source Detail\n",
        "lead_source_counts = converted_leads['Lead Source'].value_counts()\n",
        "lead_source_detail_counts = converted_leads['Lead Source Detail'].value_counts()\n",
        "\n",
        "# Combine the counts into a DataFrame\n",
        "combined_counts = pd.concat([lead_source_counts, lead_source_detail_counts], axis=1).fillna(0)\n",
        "combined_counts.columns = ['Lead Source', 'Lead Source Detail']\n",
        "\n",
        "# Select the top 5 categories overall\n",
        "top_combined_counts = combined_counts.sum(axis=1).nlargest(5)\n",
        "top_combined_counts = combined_counts.loc[top_combined_counts.index]\n",
        "\n",
        "# Create the bar chart\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = range(len(top_combined_counts))\n",
        "\n",
        "# Plot Lead Source bars\n",
        "lead_source_bars = ax.bar(index, top_combined_counts['Lead Source'], bar_width, label='Lead Source', color='skyblue')\n",
        "\n",
        "# Plot Lead Source Detail bars next to Lead Source bars\n",
        "lead_source_detail_bars = ax.bar([i + bar_width for i in index], top_combined_counts['Lead Source Detail'], bar_width, label='Lead Source Detail', color='salmon')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Category')\n",
        "ax.set_ylabel('Number of Converted Leads')\n",
        "ax.set_title('Top 5 Lead Sources and Lead Source Details for Converted Leads')\n",
        "ax.set_xticks([i + bar_width / 2 for i in index])\n",
        "ax.set_xticklabels(top_combined_counts.index, rotation=45)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ph_ol5Exd9ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frequency_and_percentage('Gender', df, df, True, 6)"
      ],
      "metadata": {
        "id": "sC76CURYd_CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frequency_and_percentage('Study Program', df, df, True, 6)"
      ],
      "metadata": {
        "id": "NfpXzm4jeAbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frequency_and_percentage('Study Model', df, df, True, 6)"
      ],
      "metadata": {
        "id": "yhXDJ-s7eCVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Study Model')"
      ],
      "metadata": {
        "id": "gMOWHJp0eECl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frequency_and_percentage('Accept Data Policy', df, df, True, 6)"
      ],
      "metadata": {
        "id": "shRf5FtveFRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Accept Data Policy')"
      ],
      "metadata": {
        "id": "XcLLQ_cYeImg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Name Case')"
      ],
      "metadata": {
        "id": "PihxF-_OeNuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frequency_and_percentage('Name Case', df, df, True, 6)"
      ],
      "metadata": {
        "id": "XGH4RaQUePQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Domain Type')"
      ],
      "metadata": {
        "id": "P4BTrnqHeQxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df[df['is_converted'] == True]\n",
        "\n",
        "# Step 3: Calculate the mean of 's_onTime' for the filtered DataFrame\n",
        "s_onTime_mean_filtered = filtered_df['Sum of Study Interests'].mean()\n",
        "print(s_onTime_mean_filtered)"
      ],
      "metadata": {
        "id": "dq6xG1sCeR-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frequency_and_percentage('has Phone', df, df, True, 6)"
      ],
      "metadata": {
        "id": "6OUk9QS6eTlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frequency_and_percentage('Name Case', df, df, True, 6)"
      ],
      "metadata": {
        "id": "HePsbnRyeU6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frequency_and_percentage('Conversion Type', df, df, True, 6)"
      ],
      "metadata": {
        "id": "1lEqzDP4eWfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Conversion Type')"
      ],
      "metadata": {
        "id": "FcYXCgXceX-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install category_encoders --q"
      ],
      "metadata": {
        "id": "p3OmI-nqfvH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
        "import category_encoders as ce"
      ],
      "metadata": {
        "id": "xB0ViCMieZvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "AjY1pu6MebOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "hVC_oWM8Mm1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Drop 'is_converted' column from df_encoded and assign to X_\n",
        "X = df.drop(columns=['is_converted'])\n",
        "\n",
        "# Step 2: Extract 'is_converted' column from df_encoded and assign to y\n",
        "y = df['is_converted']"
      ],
      "metadata": {
        "id": "ib-lFDqledy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "one_hot_features = ['Host', 'Conversion Type', 'Gender', 'Study Model',  'Faculty', 'Study Location', 'Type of Study Program',\n",
        "                  'Lead Source', 'Accept Data Policy', 'has Phone', 'Domain Type', 'Name Case', 'Lead Source Detail', 'Study Program', 'Semester']\n",
        "\n",
        "X = pd.get_dummies(X, columns=one_hot_features)"
      ],
      "metadata": {
        "id": "JoIJHmM4OduM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Scaling the dataframe\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Step 7: Define the encoded and scaled dataframe as X_prep\n",
        "X_prep = X_scaled"
      ],
      "metadata": {
        "id": "u4m7KJCdeftx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lb = LabelEncoder()\n",
        "lb.fit(y)\n",
        "y_encoded = lb.transform(y)\n",
        "print(\"Encoded labels:\",lb.classes_)\n",
        "y_en = pd.Series(y_encoded)"
      ],
      "metadata": {
        "id": "1KibOzUiVBRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_prep, y_en, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "\n",
        "print(\"Training Data Shape : \", X_train.shape, y_train.shape)\n",
        "print(\"Test Data Shape : \", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "Vk_Xpdq9ehVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Initialize SMOTENC with Nearest Neighbors Estimator\n",
        "smote= SMOTE(random_state=42)\n",
        "\n",
        "# Fit and resample the training data\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "_HHK5_MpeiiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Smote Train Data : \", X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "id": "3X_2gZ0vekAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Mutual Information scores\n",
        "mi_classification = mutual_info_classif(X_train, y_train, discrete_features='auto')\n",
        "\n",
        "# Create a pandas Series with the MI scores and the feature names\n",
        "mi_series = pd.Series(mi_classification, index=X_train.columns)\n",
        "\n",
        "# Exclude the specified column\n",
        "mi_series = mi_series.drop(labels='Sum of Study Interests')\n",
        "\n",
        "# Sort the MI scores in descending order and convert to a DataFrame\n",
        "data_mi = mi_series.sort_values(ascending=False).to_frame(name='MI')\n",
        "\n",
        "# Display the DataFrame\n",
        "print(data_mi)\n"
      ],
      "metadata": {
        "id": "o6tSlhHhelHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot the Mutual Information scores\n",
        "def plot_mi_scores(scores):\n",
        "    # Select top 10 scores\n",
        "    top_scores = scores.sort_values(ascending=False).head(30)\n",
        "    sorted_scores = top_scores.sort_values(ascending=True)\n",
        "    width = np.arange(len(sorted_scores))\n",
        "    ticks = sorted_scores.index\n",
        "    plt.barh(width, sorted_scores)\n",
        "    plt.yticks(width, ticks)\n",
        "    plt.title(\"Top 10 Mutual Information Scores\")\n",
        "    plt.xlabel(\"Score\")\n",
        "    plt.ylabel(\"Features\")\n",
        "\n",
        "    # Add text annotations for the bar values\n",
        "    for index, value in enumerate(sorted_scores):\n",
        "        plt.text(value, index, f'{value:.2f}', va='center', ha='left')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot the Mutual Information scores\n",
        "plt.figure(dpi=100, figsize=(8, 5))\n",
        "plot_mi_scores(mi_series)\n",
        "\n"
      ],
      "metadata": {
        "id": "UMhL78s6empN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "# Filter data based on Mutual Information scores\n",
        "filtered_data_mi = data_mi[data_mi['MI'] >= 0.01]\n",
        "\n",
        "# Ensure indices match with X_train and X_temp columns\n",
        "common_indices = filtered_data_mi.index.intersection(X_train.columns)\n",
        "filtered_data_mi = filtered_data_mi.loc[common_indices]\n",
        "\n",
        "# Apply the filtered indices to X_train and X_temp\n",
        "X_train = X_train[common_indices]\n",
        "X_temp = X_temp[common_indices]\n",
        "'''"
      ],
      "metadata": {
        "id": "pXexrnBAgL2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.feature_selection import f_classif\n",
        "from scipy import stats\n",
        "\n",
        "X = df[['Sum of Study Interests']]\n",
        "y = df['is_converted']\n",
        "\n",
        "# Apply ANOVA F-test\n",
        "f_values, p_values = f_classif(X, y)\n",
        "\n",
        "# Create a DataFrame to display the F-scores and p-values for the specific feature\n",
        "anova_results = pd.DataFrame({\n",
        "    'Feature': ['Sum of Study Interests'],\n",
        "    'F-Score': f_values,\n",
        "    'p-Value': p_values\n",
        "})\n",
        "\n",
        "# Select the feature (in this case, it's already just one)\n",
        "selected_feature = anova_results.iloc[0]\n",
        "\n",
        "print(\"Selected feature based on ANOVA F-test:\")\n",
        "print(selected_feature)"
      ],
      "metadata": {
        "id": "4cL1PcdjeoZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "# Verify the distribution\n",
        "print(\"Training set distribution:\", Counter(y_train))\n",
        "print(\"Test set distribution:\", Counter(y_test))"
      ],
      "metadata": {
        "id": "ZnLvitO8Wc6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate models\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    predictions = model.predict(X_test)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        proba = model.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        proba = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    roc_auc = roc_auc_score(y_test, proba)\n",
        "\n",
        "    cm = confusion_matrix(y_test, predictions)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    print(f\"{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall (Sensitivity): {recall}\")\n",
        "    print(f\"F1-Score: {f1}\")\n",
        "    print(f\"Specificity: {specificity}\")\n",
        "    print(f\"ROC AUC: {roc_auc}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
        "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_name} ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Converted', 'Converted'], yticklabels=['Not Converted', 'Converted'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc,\n",
        "        'specificity': specificity\n",
        "    }"
      ],
      "metadata": {
        "id": "sg0jUrfterIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DNN model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Define the DNN model\n",
        "def create_dnn_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "OA9DfAdKeshR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "# Pipelines for each model\n",
        "pipeline_xgb = Pipeline([\n",
        "    ('clf', xgb.XGBClassifier())\n",
        "])\n",
        "\n",
        "pipeline_rf = Pipeline([\n",
        "    ('clf', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "pipeline_dt = Pipeline([\n",
        "    ('clf', DecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "pipeline_dnn = Pipeline([\n",
        "    ('clf', KerasClassifier(build_fn=lambda: create_dnn_model(input_dim), epochs=50, batch_size=32, verbose=0))\n",
        "])"
      ],
      "metadata": {
        "id": "LPF99xlZe4T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models without cross-validation\n",
        "model_performance = {}"
      ],
      "metadata": {
        "id": "3n_tg0e4e7Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train and evaluate XGBoost\n",
        "model_performance['XGBoost'] = evaluate_model(pipeline_xgb.fit(X_train, y_train),X_test, y_test, \"XGBoost\")"
      ],
      "metadata": {
        "id": "_hiZvDOGJsg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train and evaluate RandomForest\n",
        "model_performance['RandomForest'] = evaluate_model(pipeline_rf.fit(X_train, y_train), X_test, y_test, \"RandomForest\")"
      ],
      "metadata": {
        "id": "kIqNLknPXCZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train and evaluate DecisionTree\n",
        "model_performance['DecisionTree'] = evaluate_model(pipeline_dt.fit(X_train, y_train), X_test, y_test, \"DecisionTree\")"
      ],
      "metadata": {
        "id": "cjbMUJjcXDqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance['DNN'] = evaluate_model(pipeline_dnn.fit(X_train, y_train), X_test, y_test, \"Deep Neural Network\")"
      ],
      "metadata": {
        "id": "uCwQdvDvXE-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the performance metrics\n",
        "for model_name, metrics in model_performance.items():\n",
        "    print(f\"\\n{model_name} Performance:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "v5k2_ze_T7L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model performance dictionary to a DataFrame\n",
        "results_df = pd.DataFrame(model_performance).T\n",
        "\n",
        "# Save results to an Excel file\n",
        "results_df.to_excel('model_performance_metrics_without_tuning_final.xlsx', index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "s85U3h6TXGcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import uniform\n",
        "param_rand_xgb = {\n",
        "    'clf__max_depth': [3, 5, 7, 9],\n",
        "    'clf__learning_rate': uniform(0.001, 0.1),\n",
        "    'clf__n_estimators': [100, 200, 300],\n",
        "    'clf__subsample': uniform(0.6, 0.4),\n",
        "    'clf__colsample_bytree': uniform(0.6, 0.4),\n",
        "    'clf__gamma': uniform(0, 0.2),\n",
        "    'clf__min_child_weight': [1, 3, 5],\n",
        "    'clf__reg_alpha': uniform(0, 0.5),\n",
        "    'clf__reg_lambda': uniform(1, 1)\n",
        "}\n",
        "\n",
        "param_rand_rf = {\n",
        "    'clf__n_estimators': [100, 200, 300, 500],\n",
        "    'clf__max_depth': [None, 10, 20, 30],\n",
        "    'clf__min_samples_split': [2, 5, 10],\n",
        "    'clf__min_samples_leaf': [1, 2, 4],\n",
        "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'clf__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "param_rand_dt = {\n",
        "    'clf__max_depth': [None, 10, 20, 30],\n",
        "    'clf__min_samples_split': [2, 5, 10],\n",
        "    'clf__min_samples_leaf': [1, 2, 4],\n",
        "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'clf__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "param_rand_dnn = {\n",
        "    'clf__num_layers': [1, 2, 3],\n",
        "    'clf__num_neurons': [16, 32, 64],\n",
        "    'clf__activation': ['relu', 'tanh'],\n",
        "    'clf__dropout_rate': uniform(0.1, 0.5),\n",
        "    'clf__optimizer': ['adam', 'rmsprop'],\n",
        "    'clf__epochs': [50, 100],\n",
        "    'clf__batch_size': [32, 64]\n",
        "}\n"
      ],
      "metadata": {
        "id": "2lnVWi6lvMjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "def perform_randomized_search(pipeline, param_rand, X_train, y_train, n_iter=100):\n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_rand,\n",
        "                                       n_iter=n_iter, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=2, random_state=42)\n",
        "    random_search.fit(X_train, y_train)\n",
        "    return random_search"
      ],
      "metadata": {
        "id": "IHc26USvkDwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_xgb = perform_randomized_search(pipeline_xgb, param_rand_xgb, X_train, y_train)"
      ],
      "metadata": {
        "id": "a_AXzDYzkGCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance = {}"
      ],
      "metadata": {
        "id": "91A22yJTkHK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance['XGBoost'] = evaluate_model(random_search_xgb, X_test, y_test, 'XGBoost')"
      ],
      "metadata": {
        "id": "RYbEORmLkIRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_rf = perform_randomized_search(pipeline_rf, param_rand_rf, X_train, y_train)"
      ],
      "metadata": {
        "id": "IrDc1v_LkJoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance['RandomForest'] = evaluate_model(random_search_rf, X_test, y_test, 'RandomForest', X_train, y_train)"
      ],
      "metadata": {
        "id": "Cr1qIwq5kLBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_dt = perform_randomized_search(pipeline_dt, param_rand_dt, X_train, y_train)"
      ],
      "metadata": {
        "id": "kPDmnSbUkMYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance['DecisionTree'] = evaluate_model(random_search_dt, X_test, y_test, 'DecisionTree', X_train, y_train)"
      ],
      "metadata": {
        "id": "mAhrSD68kPLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_dnn = perform_randomized_search(pipeline_dnn, param_rand_dnn, X_train, y_train)"
      ],
      "metadata": {
        "id": "1OnxR0OakbuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance['DNN'] = evaluate_model(random_search_dnn, X_test, y_test, \"Deep Neural Network\")"
      ],
      "metadata": {
        "id": "f4vJ0W9tkcWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the performance metrics\n",
        "for model_name, metrics in model_performance.items():\n",
        "    print(f\"\\n{model_name} Performance:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "JeuuW6vakQ6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best parameters\n",
        "print(\"\\nBest Parameters:\")\n",
        "print(perform_randomized_search.best_params_)"
      ],
      "metadata": {
        "id": "4wUxoDm5v9az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model performance dictionary to a DataFrame\n",
        "results_df = pd.DataFrame(model_performance).T\n",
        "\n",
        "# Save results to an Excel file\n",
        "results_df.to_excel('model_performance_metrics_final.xlsx', index=True)\n",
        "\n",
        "# Print results for each model\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "7j775mVbwFYO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}