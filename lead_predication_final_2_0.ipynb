{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincelemke99/Bachelor-Thesis/blob/main/lead_predication_final_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VMJ5cPLBVdfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa95af7-65b3-46fe-d85c-8adc49bfb784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m71.7/81.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pandas category_encoders scikit-learn --q\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3T_tHqDzWZbe"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "# Import machine learning libraries\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    confusion_matrix\n",
        ")\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import mutual_info_classif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT7VAX41WnIm"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print(\"Authenticated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGboKyEQWr-r"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = 'prj-snd-ew3-vschmitt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nsljx4HWxGd"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BfCcMo_Wya1"
      },
      "outputs": [],
      "source": [
        "BQ_PROJECT = PROJECT_ID\n",
        "BQ_DATASET = 'lead_prediction'\n",
        "BQ_TABLE = 'trainings_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVoL7y-jW0iE"
      },
      "outputs": [],
      "source": [
        "# SQL query to select data\n",
        "query = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    # Execute the query and convert the result to a pandas DataFrame\n",
        "    df = client.query(query=query).to_dataframe()\n",
        "    print(\"Query executed successfully and DataFrame is ready.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLbjT2UIXEKJ"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAxNXVBKXCjg"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avgvLPSaXS5R"
      },
      "outputs": [],
      "source": [
        "df.drop(['Lead_ID',], axis=\"columns\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znfJYTaoXTuY"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={'Lead_Source' : 'Lead Source', 'Lead_Source_Detail' : 'Lead Source Detail',\n",
        "                   'Name_Case' : 'Name Case', 'has_Phone' : 'has Phone', 'Accept_Data_Policy' : 'Accept Data Policy',\n",
        "                   'Conversion_Type' : 'Conversion Type', 'Study_Model' : 'Study Model', 'Type_of_Study_Program' : 'Type of Study Program',\n",
        "                   'Study_Location' : 'Study Location', 'Study_Program' : 'Study Program', 'Sum_of_Study_Interests' : 'Sum of Study Interests' , 'Domain_Type' : 'Domain Type' },inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZacqJtFTPd_f"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqUlCymKbAY1"
      },
      "outputs": [],
      "source": [
        "df.isna().sum().to_frame(name='Missing Values').sort_values('Missing Values', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLW5UUU_bMCX"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of missing values for each column\n",
        "percentage_missing = df.isnull().sum() * 100 / len(df)\n",
        "# Create a DataFrame to display the missing values\n",
        "missing_values_df = percentage_missing.to_frame(name='Missing Values').sort_values('Missing Values', ascending=False)\n",
        "# Display the DataFrame\n",
        "missing_values_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cqMn6vvfw0j"
      },
      "outputs": [],
      "source": [
        "df['Host'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpr998l9PpBA"
      },
      "outputs": [],
      "source": [
        "unwanted_hosts = ['staging.hs-fresenius.de', 'hsf035.dev.360vier.net', 'b2uxwopd.myraidbox.de', 'digital-health-school.de']\n",
        "\n",
        "# Filter the DataFrame\n",
        "df = df[~df['Host'].isin(unwanted_hosts)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doZ8Ys66Psy_"
      },
      "outputs": [],
      "source": [
        "unwanted_Lead_Source = ['-149307507Publisher', 'Not Found']\n",
        "\n",
        "# Filter the DataFrame\n",
        "df = df[~df['Lead Source'].isin(unwanted_Lead_Source )]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtOdnT0YPup8"
      },
      "outputs": [],
      "source": [
        "df['Conversion Type'] = df['Conversion Type'].fillna('Infomaterial')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj221V98PvFu"
      },
      "outputs": [],
      "source": [
        "df['Gender'] = df['Gender'].fillna('weiblich')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj9F95mzP3wZ"
      },
      "outputs": [],
      "source": [
        "df['Host'] = df['Host'].fillna('www.hs-fresenius.de')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71wodbBsPw1x"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfshCN_QgkmL"
      },
      "outputs": [],
      "source": [
        "df.isna().sum().to_frame(name='Missing Values').sort_values('Missing Values', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTdhXBaTiNK3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "sns.countplot(x='is_converted', data=df)\n",
        "plt.title('No of Unsuccessful Leads vs Successful Converted Leads', color='blue')\n",
        "plt.xticks(np.arange(2), ('Unsuccessful', 'Successful'))\n",
        "plt.xlabel('Conversion Status')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4f8TmKqE6Vo"
      },
      "outputs": [],
      "source": [
        "total_leads = len(df)\n",
        "successful_leads = df['is_converted'].sum()\n",
        "conversion_rate = (successful_leads / total_leads) * 100\n",
        "print(f'Conversion Rate: {conversion_rate:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLR6EcKAJ2Ak"
      },
      "outputs": [],
      "source": [
        "# Creating a crosstab DataFrame for demonstration\n",
        "crosstab_df = pd.crosstab(index=df['Lead Source'], columns='count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO-qD1wHsVFM"
      },
      "outputs": [],
      "source": [
        "def plot_frequency_and_percentage(feature, df, category_df, another_row=False, height=8, ylabels=[]):\n",
        "    if another_row:\n",
        "        fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10, height * 2))\n",
        "    else:\n",
        "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 6))\n",
        "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "\n",
        "    # Get top 5 categories by frequency\n",
        "    top_categories = category_df[feature].value_counts().nlargest(5).index\n",
        "\n",
        "    # Frequency plot for top 5 categories\n",
        "    ax1.set_title(f'Frequency Plot of {feature}', color='blue')\n",
        "    ax1.set_ylabel(feature)\n",
        "    ax1.set_xlabel('count')\n",
        "    sns.countplot(y=feature, data=category_df[category_df[feature].isin(top_categories)],\n",
        "                  order=top_categories, ax=ax1, color='green')\n",
        "    if ylabels:\n",
        "        ax1.set_yticklabels(ylabels)\n",
        "\n",
        "    # Calculate count of converted leads for top 5 categories\n",
        "    converted_counts = df[df['is_converted'] == True][feature].value_counts()\n",
        "    converted_counts = converted_counts[converted_counts.index.isin(top_categories)]\n",
        "\n",
        "    # Converted leads plot for top 5 categories\n",
        "    ax2.set_title('Converted Leads Count', color='blue')\n",
        "    ax2.set_ylabel(feature)\n",
        "    ax2.set_xlabel('count')\n",
        "    converted_counts.sort_values().plot(kind='barh', ax=ax2, color='orange')\n",
        "    if ylabels:\n",
        "        ax2.set_yticklabels(ylabels)\n",
        "\n",
        "    # Calculate and display overall conversion rate\n",
        "    total_leads = len(df)\n",
        "    successful_leads = df['is_converted'].sum()\n",
        "    conversion_rate = (successful_leads / total_leads) * 100\n",
        "    fig.suptitle(f'Overall Conversion Rate: {conversion_rate:.2f}%', fontsize=14, color='red')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSIe_igLbXYB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_conversion_rate(df, is_converted_column, feature):\n",
        "    \"\"\"\n",
        "    Plots the conversion rate for a specified feature.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): The dataframe containing the data.\n",
        "    is_converted_column (str): The name of the column indicating if a conversion occurred.\n",
        "    feature (str): The feature for which to calculate and plot the conversion rate.\n",
        "    \"\"\"\n",
        "    # Filter data where is_converted is True\n",
        "    df_converted = df[df[is_converted_column] == True]\n",
        "\n",
        "    # Calculate the count of conversions for each unique value in the feature\n",
        "    converted_counts = df_converted[feature].value_counts()\n",
        "\n",
        "    # Calculate the percentage of each unique value within the converted data\n",
        "    conversion_rate = (converted_counts / converted_counts.sum()) * 100\n",
        "    conversion_rate = conversion_rate.sort_values(ascending=False)\n",
        "\n",
        "    # Plot bar chart\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    conversion_rate.plot(kind='bar')\n",
        "    plt.title(f'Percentage of Converted Users by {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Percentage of Converted Users (%)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9WrvhktM6pe"
      },
      "outputs": [],
      "source": [
        "plot_frequency_and_percentage('Lead Source', df, df, True, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxbY1qMsQtC9"
      },
      "outputs": [],
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Lead Source')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE2Q19OctYQE"
      },
      "outputs": [],
      "source": [
        "#plot_frequency_and_percentage('Lead_Source_Detail', df, df, True, 6)\n",
        "plot_frequency_and_percentage('Lead Source Detail', df, df, another_row=False, height=8, ylabels=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtfpDSBBvJYS"
      },
      "outputs": [],
      "source": [
        "plot_frequency_and_percentage('Gender', df, df, True, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wADq3OEzvUwb"
      },
      "outputs": [],
      "source": [
        "plot_frequency_and_percentage('Study Program', df, df, True, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAPTbSR_vqEV"
      },
      "outputs": [],
      "source": [
        "plot_frequency_and_percentage('Study Model', df, df, True, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A5vB0L0XGZK"
      },
      "outputs": [],
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Study Model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOEIohXsqdhN"
      },
      "outputs": [],
      "source": [
        "plot_frequency_and_percentage('Accept Data Policy', df, df, True, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7obS1NTcYJae"
      },
      "outputs": [],
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Accept Data Policy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhwjNpl-cjNa"
      },
      "outputs": [],
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Name Case')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JESIbqT4cq39"
      },
      "outputs": [],
      "source": [
        "plot_frequency_and_percentage('Name Case', df, df, True, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzEky2rfc2MM"
      },
      "outputs": [],
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Domain Type')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gobxlsSBo8P"
      },
      "outputs": [],
      "source": [
        "filtered_df = df[df['is_converted'] == True]\n",
        "\n",
        "# Step 3: Calculate the mean of 's_onTime' for the filtered DataFrame\n",
        "s_onTime_mean_filtered = filtered_df['Sum of Study Interests'].mean()\n",
        "print(s_onTime_mean_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXw4pSAM0an5"
      },
      "outputs": [],
      "source": [
        "plot_frequency_and_percentage('has Phone', df, df, True, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np9y1ykG58wY"
      },
      "outputs": [],
      "source": [
        "plot_frequency_and_percentage('Name Case', df, df, True, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAi2O_kRdq3B"
      },
      "outputs": [],
      "source": [
        "plot_frequency_and_percentage('Conversion Type', df, df, True, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy4vqjhVdvog"
      },
      "outputs": [],
      "source": [
        "plot_conversion_rate(df, 'is_converted', 'Conversion Type')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkuONHsvh_t9"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
        "import category_encoders as ce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrxW2hDJj7AE"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAk-jgDfkbg2"
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrmNEAl-rLjf"
      },
      "outputs": [],
      "source": [
        "# Create a copy of the dataframe to work with\n",
        "df_encoded = df.copy()\n",
        "\n",
        "# Step 1: Drop 'is_converted' column from df_encoded and assign to X_\n",
        "X = df_encoded.drop(columns=['is_converted'])\n",
        "\n",
        "# Step 2: Extract 'is_converted' column from df_encoded and assign to y\n",
        "y = df_encoded['is_converted']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnX877N85qx0"
      },
      "outputs": [],
      "source": [
        "# Step 3: Label Encoding for specified column\n",
        "\n",
        "#binary_features = ['Lead Source Detail', 'Study Program']\n",
        "##encoder_target = ce.TargetEncoder(cols=binary_features)\n",
        "#X = encoder_target.fit_transform(X, y)\n",
        "\n",
        "one_hot_features = ['Host', 'Conversion Type', 'Gender', 'Study Model',  'Faculty', 'Study Location', 'Type of Study Program',\n",
        "                  'Lead Source', 'Accept Data Policy', 'has Phone', 'Domain Type', 'Name Case', 'Lead Source Detail', 'Study Program', 'Semester']\n",
        "\n",
        "X = pd.get_dummies(X, columns=one_hot_features)\n",
        "\n",
        "\n",
        "\n",
        "# Step 6: Scaling the dataframe\n",
        "scaler = StandardScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Step 7: Define the encoded and scaled dataframe as X_prep\n",
        "X_en = df_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmG13Zq3Zj6F"
      },
      "outputs": [],
      "source": [
        "# Step 4: Identify categorical features indices for SMOTENC\n",
        "#categorical_columns = [col for col in X.columns if col not in ['Sum of Study Interests']]\n",
        "\n",
        "#all_columns = X_en.columns.tolist()\n",
        "#categorical_indices = [all_columns.index(col) for col in categorical_columns if col in all_columns]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D61iTfpi0-H1"
      },
      "outputs": [],
      "source": [
        "lb = LabelEncoder()\n",
        "lb.fit(y)\n",
        "y_encoded = lb.transform(y)\n",
        "print(\"Encoded labels:\",lb.classes_)\n",
        "y_en = pd.Series(y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpDxV4bQquTY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_en, y_en, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "\n",
        "print(\"Training Data Shape : \", X_train.shape, y_train.shape)\n",
        "print(\"Test Data Shape : \", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwPg2jn4eS_T"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pandas as pd\n",
        "import time\n",
        "'''\n",
        "# Check available columns in X_train\n",
        "print(\"Columns in X_train:\", X_train.columns.tolist())\n",
        "\n",
        "# Define the list of original categorical columns before one-hot encoding\n",
        "original_categorical_columns = [\n",
        "    'Host', 'Conversion Type', 'Gender', 'Study Model', 'Faculty', 'Study Location', 'Type of Study Program',\n",
        "    'Lead Source', 'Accept Data Policy', 'has Phone', 'Domain Type', 'Name Case', 'Lead Source Detail',\n",
        "    'Study Program', 'Semester'\n",
        "]\n",
        "\n",
        "# Function to get one-hot encoded columns for a given original categorical column\n",
        "def get_one_hot_encoded_columns(original_column_name, all_columns):\n",
        "    return [col for col in all_columns if col.startswith(original_column_name + '_')]\n",
        "\n",
        "# Extract indices of one-hot encoded columns\n",
        "categorical_features_indices = []\n",
        "missing_columns = []\n",
        "\n",
        "for original_col in original_categorical_columns:\n",
        "    encoded_columns = get_one_hot_encoded_columns(original_col, X_train.columns)\n",
        "    if encoded_columns:\n",
        "        categorical_features_indices.extend([X_train.columns.get_loc(col) for col in encoded_columns])\n",
        "    else:\n",
        "        missing_columns.append(original_col)\n",
        "\n",
        "if missing_columns:\n",
        "    print(\"Warning: The following original columns have no corresponding one-hot encoded columns in X_train:\", missing_columns)\n",
        "\n",
        "# Proceed if there are valid categorical features\n",
        "\n",
        "'''\n",
        "'''\n",
        "categorical_columns = [col for col in X.columns if col not in ['Sum of Study Interests']]\n",
        "\n",
        "all_columns = X_en.columns.tolist()\n",
        "categorical_indices = [all_columns.index(col) for col in categorical_columns if col in all_columns]\n",
        "\n",
        "if categorical_indices:\n",
        "   # Nearest Neighbors Estimator mit Parallelisierung\n",
        "    nn_estimator = NearestNeighbors(n_neighbors=5, n_jobs=-1)\n",
        "\n",
        "    # Initialize SMOTENC with Nearest Neighbors Estimator\n",
        "    smotenc = SMOTENC(categorical_features=categorical_indices, random_state=42, k_neighbors=nn_estimator)\n",
        "\n",
        "    # Start timing\n",
        "    print(\"Start der Berechnung von SMOTENC...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Fit and resample the training data\n",
        "    X_train, y_train = smotenc.fit_resample(X_train, y_train)\n",
        "\n",
        "    # End timing\n",
        "    end_time = time.time()\n",
        "    print(\"SMOTENC Berechnung abgeschlossen.\")\n",
        "    print(f\"Dauer der Berechnung: {end_time - start_time:.2f} Sekunden\")\n",
        "else:\n",
        "    print(\"No valid categorical features found. SMOTENC will not be applied.\")\n",
        "    '''\n",
        "# Start timing\n",
        "print(\"Start der Berechnung von SMOTE...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42, k_neighbors=5, n_jobs=-1)\n",
        "\n",
        "# Fit and resample the training data\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# End timing\n",
        "end_time = time.time()\n",
        "print(\"SMOTE Berechnung abgeschlossen.\")\n",
        "print(f\"Dauer der Berechnung: {end_time - start_time:.2f} Sekunden\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_MdL3dy6s9r"
      },
      "outputs": [],
      "source": [
        "print(\"Smote Train Data : \", X_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toI2dm158YDx"
      },
      "outputs": [],
      "source": [
        "# Compute Mutual Information scores\n",
        "mi_classification = mutual_info_classif(X_train, y_train, discrete_features='auto')\n",
        "\n",
        "# Create a pandas Series with the MI scores and the feature names\n",
        "mi_series = pd.Series(mi_classification, index=X_train.columns)\n",
        "\n",
        "# Exclude the specified column\n",
        "mi_series = mi_series.drop(labels='Sum of Study Interests')\n",
        "\n",
        "# Sort the MI scores in descending order and convert to a DataFrame\n",
        "data_mi = mi_series.sort_values(ascending=False).to_frame(name='MI')\n",
        "\n",
        "# Display the DataFrame\n",
        "print(data_mi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4D8xhecOs0M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot the Mutual Information scores\n",
        "def plot_mi_scores(scores):\n",
        "    # Select top 10 scores\n",
        "    top_scores = scores.sort_values(ascending=False).head(30)\n",
        "    sorted_scores = top_scores.sort_values(ascending=True)\n",
        "    width = np.arange(len(sorted_scores))\n",
        "    ticks = sorted_scores.index\n",
        "    plt.barh(width, sorted_scores)\n",
        "    plt.yticks(width, ticks)\n",
        "    plt.title(\"Top 10 Mutual Information Scores\")\n",
        "    plt.xlabel(\"Score\")\n",
        "    plt.ylabel(\"Features\")\n",
        "\n",
        "    # Add text annotations for the bar values\n",
        "    for index, value in enumerate(sorted_scores):\n",
        "        plt.text(value, index, f'{value:.2f}', va='center', ha='left')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot the Mutual Information scores\n",
        "plt.figure(dpi=100, figsize=(8, 5))\n",
        "plot_mi_scores(mi_series)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8Ws05oh8rNn"
      },
      "outputs": [],
      "source": [
        "one_hot_features = ['Host', 'Conversion Type', 'Gender', 'Study Model',  'Faculty', 'Study Location', 'Type of Study Program',\n",
        "                  'Lead Source', 'Accept Data Policy', 'has Phone', 'Domain Type', 'Name Case', 'Lead Source Detail', 'Study Program', 'Semester']  # Replace with actual prefixes\n",
        "aggregated_mi = {}\n",
        "for col in mi_series.index:\n",
        "    if any(prefix in col for prefix in one_hot_features):\n",
        "        original_col = next(prefix for prefix in one_hot_features if prefix in col)\n",
        "        if original_col not in aggregated_mi:\n",
        "            aggregated_mi[original_col] = 0\n",
        "        aggregated_mi[original_col] += mi_series[col]\n",
        "    else:\n",
        "        aggregated_mi[col] = mi_series[col]\n",
        "\n",
        "# Convert the aggregated MI scores to a DataFrame\n",
        "aggregated_mi_series = pd.Series(aggregated_mi)\n",
        "data_mi = aggregated_mi_series.sort_values(ascending=False).to_frame(name='MI')\n",
        "\n",
        "# Display the DataFrame\n",
        "print(data_mi)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "data_mi['MI'].plot(kind='bar')\n",
        "plt.title('Feature Importance using Mutual Information')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Mutual Information Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9m6Q1X5e9W-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from scipy import stats\n",
        "\n",
        "# Assuming 'Sum of Study Interests' is a column in X_train\n",
        "# Extract the specific feature\n",
        "feature_name = 'Sum of Study Interests'\n",
        "X_feature = X_train[feature_name]\n",
        "\n",
        "# Assuming 'is_converted' is a column in y_train\n",
        "target_name = 'is_converted'\n",
        "y_target = y_train[target_name]\n",
        "\n",
        "# Combine into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'Feature': X_feature,\n",
        "    'Target': y_target\n",
        "})\n",
        "\n",
        "# Perform ANOVA using statsmodels\n",
        "model = ols('Target ~ C(Feature)', data=data).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(\"Detailed ANOVA using statsmodels\")\n",
        "print(anova_table)\n",
        "\n",
        "# Perf\n"
      ],
      "metadata": {
        "id": "He1opi7CHqC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piHwO2J1M5XC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "cv_split = StratifiedKFold(n_splits=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD0OaCweV2xg"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    predictions = model.predict(X_test)\n",
        "    proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    roc_auc = roc_auc_score(y_test, proba)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, predictions)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Cross Validation\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "    print(f\"{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall (Sensitivity): {recall}\")\n",
        "    print(f\"F1-Score: {f1}\")\n",
        "    print(f\"Specificity: {specificity}\")\n",
        "    print(f\"ROC AUC: {roc_auc}\")\n",
        "    print(f\"Cross Validation Accuracy: {cv_scores.mean()}\")\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
        "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_name} ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion Matrix Visualization\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Converted', 'Converted'], yticklabels=['Not Converted', 'Converted'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc,\n",
        "        'specificity': specificity,\n",
        "        'cv_accuracy': cv_scores.mean()\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "690w7MhJWjM9"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "# Pipelines for each model without hyperparameter tuning\n",
        "\n",
        "pipeline_xgb = Pipeline([\n",
        "    ('clf', xgb.XGBClassifier())\n",
        "])\n",
        "\n",
        "pipeline_rf = Pipeline([\n",
        "    ('clf', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "pipeline_dt = Pipeline([\n",
        "    ('clf', DecisionTreeClassifier())\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMqn3i6XWSmU"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_performance = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7ab1THTEmD9"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate XGBoost\n",
        "model_performance['XGBoost'] = evaluate_model(pipeline_xgb.fit(X_train, y_train),X_test, y_test, \"XGBoost\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzZLpzYqEnWk"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate RandomForest\n",
        "model_performance['RandomForest'] = evaluate_model(pipeline_rf.fit(X_train, y_train), X_test, y_test, \"RandomForest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fzx8IkREo8B"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate DecisionTree\n",
        "model_performance['DecisionTree'] = evaluate_model(pipeline_dt.fit(X_train, y_train), X_test, y_test, \"DecisionTree\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lgrKcRkEqIO"
      },
      "outputs": [],
      "source": [
        "# Convert the model performance dictionary to a DataFrame\n",
        "results_df = pd.DataFrame(model_performance).T\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "results_df.to_excel('model_performance_results5.xlsx', index=True)\n",
        "print(\"Model performance results saved to 'model_performance_results_final.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WW2_GTtEsSJ"
      },
      "outputs": [],
      "source": [
        "# Determine the best model based on ROC AUC\n",
        "best_model_name = max(model_performance, key=lambda k: model_performance[k]['roc_auc'])\n",
        "print(f\"The best model is {best_model_name} based on ROC AUC.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igWJfO_TwWtU"
      },
      "outputs": [],
      "source": [
        " #Define hyperparameters for Grid Search\n",
        "\n",
        "\n",
        "param_grid_xgb = {\n",
        "    #'clf__max_depth': [3, 5, 7],\n",
        "    #'clf__learning_rate': [0.1, 0.01],\n",
        "    #'clf__n_estimators': [100, 200]\n",
        "\n",
        "    'clf__max_depth': [3, 5, 7, 9, 11],\n",
        "    'clf__learning_rate': [0.1, 0.01, 0.001],\n",
        "    'clf__n_estimators': [100, 200, 300],\n",
        "    'clf__subsample': [0.6, 0.8, 1.0],\n",
        "    'clf__colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'clf__gamma': [0, 0.1, 0.2],\n",
        "    'clf__min_child_weight': [1, 3, 5],\n",
        "    'clf__reg_alpha': [0, 0.1, 0.5],\n",
        "    'clf__reg_lambda': [1, 1.5, 2]\n",
        "}\n",
        "\n",
        "\n",
        "param_grid_rf = {\n",
        "    #'clf__n_estimators': [100, 200],\n",
        "    #'clf__max_depth': [None, 10, 20]\n",
        "    'clf__n_estimators': [100, 200, 300, 500],\n",
        "    'clf__max_depth': [None, 10, 20, 30],\n",
        "    'clf__min_samples_split': [2, 5, 10],\n",
        "    'clf__min_samples_leaf': [1, 2, 4],\n",
        "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'clf__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "param_grid_dt = {\n",
        "    #'clf__max_depth': [None, 10, 20],\n",
        "    #'clf__min_samples_split': [2, 10, 20]\n",
        "    'clf__max_depth': [None, 10, 20, 30],\n",
        "    'clf__min_samples_split': [2, 10, 20, 30],\n",
        "    'clf__min_samples_leaf': [1, 2, 4, 6],\n",
        "    'clf__max_features': ['auto', 'sqrt', 'log2']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeEAVtVjwaee"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "#Function to perform Grid Search\n",
        "def perform_grid_search(pipeline, param_grid, X_train, y_train):\n",
        "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laxvrSkPwkAq"
      },
      "outputs": [],
      "source": [
        "# Perform Grid Search for each model\n",
        "#grid_search_lgb = perform_grid_search(pipeline_lgb, param_grid_lgb, X_train, y_train)\n",
        "grid_search_xgb = perform_grid_search(pipeline_xgb, param_grid_xgb, X_train, y_train)\n",
        "grid_search_rf = perform_grid_search(pipeline_rf, param_grid_rf, X_train, y_train)\n",
        "grid_search_dt = perform_grid_search(pipeline_dt, param_grid_dt, X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2LLKV74xX7T"
      },
      "outputs": [],
      "source": [
        "# Evaluate models and store performance\n",
        "model_performance = {}\n",
        "# Function to evaluate model\n",
        "def evaluate_model(grid_search, X_test, y_test, model_name, X_train, y_train):\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn = cm[0][0]\n",
        "    fp = cm[0][1] if len(cm[0]) > 1 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "    print(f\"{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall (Sensitivity): {recall}\")\n",
        "    print(f\"F1-Score: {f1}\")\n",
        "    print(f\"Specificity: {specificity}\")\n",
        "    print(f\"ROC AUC: {roc_auc}\")\n",
        "    print(f\"Cross Validation Accuracy: {cv_scores.mean()}\")\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
        "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_name} ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion Matrix Visualization\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc,\n",
        "        'specificity': specificity,\n",
        "        'cv_accuracy': cv_scores.mean(),\n",
        "        'best_params': grid_search.best_params_\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vx-rvc-zwnTm"
      },
      "outputs": [],
      "source": [
        "model_performance['XGBoost'] = evaluate_model(grid_search_xgb, X_test, y_test, 'XGBoost', X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2nyEMRuwoQb"
      },
      "outputs": [],
      "source": [
        "model_performance['RandomForest'] = evaluate_model(grid_search_rf, X_test, y_test, 'RandomForest', X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_2KxeKWwpRr"
      },
      "outputs": [],
      "source": [
        "model_performance['DecisionTree'] = evaluate_model(grid_search_dt, X_test, y_test, 'DecisionTree', X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BXTZ65r1o7j"
      },
      "outputs": [],
      "source": [
        "# Convert the model performance dictionary to a DataFrame\n",
        "results_df = pd.DataFrame(model_performance).T\n",
        "\n",
        "# Save results to an Excel file\n",
        "results_df.to_excel('model_performance_metrics_final.xlsx', index=True)\n",
        "\n",
        "# Print results for each model\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqWL8VTT_B-r"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM `prj-snd-ew3-vschmitt.lead_prediction.validation_data`\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    df = client.query(query=query).to_dataframe()\n",
        "    print(\"Query executed successfully and DataFrame is ready.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pbkTUMY_MWd"
      },
      "outputs": [],
      "source": [
        "target_column = 'is_converted'\n",
        "X_new = df.drop(columns=[target_column])\n",
        "y_new = df[target_column]\n",
        "scaler = StandardScaler()\n",
        "X_new_scaled = scaler.fit_transform(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL57_ogf_OIP"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "model_path = 'path_to_your_saved_model.pkl'\n",
        "with open(model_path, 'rb') as file:\n",
        "    model = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raEeWlp0_QuD"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_new_scaled)\n",
        "results_df = pd.DataFrame({\n",
        "    'Predictions': predictions,\n",
        "    #'True Labels': y_new  # Optional: include true labels if available\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUsJ056Z_UB5"
      },
      "outputs": [],
      "source": [
        "destination_table = 'prj-snd-ew3-vschmitt.lead_prediction.validation_data_model'\n",
        "try:\n",
        "    results_df.to_gbq(destination_table, if_exists='replace')\n",
        "    print(f\"Results successfully saved to {destination_table}.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving results to BigQuery: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}